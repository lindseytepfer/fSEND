{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c15727a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f53d35",
   "metadata": {},
   "source": [
    "### Separating out audio files from video for later selective muting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbbd8ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_path = \"/Users/f004p74/Documents/dartmouth/projects/fSEND/stimuli/narrated-thought/\"\n",
    "dirlist = os.listdir(stimuli_path)\n",
    "vidlist = [x for x in dirlist if ('.mp4') in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc0b51dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stutter', 'physical']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a,b in enumerate(vidlist):\n",
    "    b = b.split(\".\")\n",
    "    vidlist[a] = b[0]\n",
    "vidlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b26f9cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in /Users/f004p74/Documents/dartmouth/projects/fSEND/stimuli/narrated-thought/stutter.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in /Users/f004p74/Documents/dartmouth/projects/fSEND/stimuli/narrated-thought/physical.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "for i in vidlist:\n",
    "    video = mp.VideoFileClip(stimuli_path+str(i)+\".mp4\")\n",
    "    video.audio.write_audiofile(stimuli_path+str(i)+\".mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23367b72",
   "metadata": {},
   "source": [
    "### Removing selections of audio from the Narrated Thought videos\n",
    "* Version 1 of stutter: muting the (potential) negatives\n",
    "* Version 2 of stutter: muting the (potential) positives\n",
    "* Version 1 of Physical:\n",
    "* Version 2 of Physical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "abb939e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_path = \"/Users/f004p74/Documents/dartmouth/projects/fSEND/stimuli/narrated-thought/\"\n",
    "dirlist = os.listdir(stimuli_path)\n",
    "audiolist = [x for x in dirlist if ('.mp3') in x]\n",
    "audio = AudioSegment.from_mp3(stimuli_path+audiolist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "239af469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter (minute, second):\n",
    "    minute_conv = minute * 60000\n",
    "    second_conv = second * 1000\n",
    "    return (minute_conv+second_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e02acb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1start = [164000,344000,425000,453000,546000,661000]\n",
    "v1stop = [175000,363000,431000,467000,560000,696000]\n",
    "v2start = [28000,177000,386000,442000,508000,600000]\n",
    "v2stop = [31000,197000,406000,443000,514000,660000]\n",
    "base_start = [0,176000,364000,432000,468000,561000]\n",
    "base_stop = [163000,343000,424000,452000,545000,660000]\n",
    "\n",
    "v1_dict = dict(zip(v1start,v1stop))\n",
    "v2_dict = dict(zip(v2start,v2stop))\n",
    "base_dict = dict(zip(base_start,base_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "66e0fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for start, stop in base_dict.items():\n",
    "    segment = audio[start:stop]\n",
    "    segment.export(stimuli_path+\"stutter_base_\"+str(start)+\"_\"+str(stop)+\".mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7d19df2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='/Users/f004p74/Documents/dartmouth/projects/fSEND/stimuli/narrated-thought/stutter_base_697000_end.mp3'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment = audio[697000:]\n",
    "segment.export(stimuli_path+\"stutter_base_697000_end.mp3\", format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "678b95a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for start, stop in v1_dict.items():\n",
    "    replace = AudioSegment.from_mp3(stimuli_path+\"removed/stutter_1_\"+str(start)+\"_\"+str(stop)+\".mp3\")\n",
    "    newfile = audio[start:stop] + replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eb038f",
   "metadata": {},
   "source": [
    "### Stitching together the files to create a reconstructed audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9767f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1path = '/Users/f004p74/Documents/dartmouth/projects/fSEND/stimuli/narrated-thought/removed/v1/'\n",
    "v1_segments = os.listdir(v1path)  \n",
    "v1_segments.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2b1b54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = AudioSegment.empty()\n",
    "\n",
    "for file in v1_segments:\n",
    "    combined += AudioSegment.from_mp3(v1path+file)\n",
    "\n",
    "combined.export(stimuli_path+\"stutter_v1.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c4d348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0790a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6a790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4d5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
