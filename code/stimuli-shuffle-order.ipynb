{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da61d510",
   "metadata": {},
   "source": [
    "# fSEND fMRI Run Sequences\n",
    "\n",
    "In this notebook, I generate .JSON files that will determine how the experimental task will present the stimuli during the scan. The paradigm includes 28 videos from the <a href=\"https://arxiv.org/abs/1912.05008\">Standford Emotional Narratives Dataset</a>, as well as two short, additional videos which involve internal narratives from the main characters of each video. \n",
    "\n",
    "The goal of this code is to shuffle all 9 runs such that their overall order varies per participant, and the videos within the runs are shuffled, such that while a run will always show the same 4 individuals, the order will vary.\n",
    "\n",
    "Additionally, the internal narrative films should also be shuffled, but not intermixed with the SEND videos; participants with even subject IDs will see the narrative films first, and the SEND videos second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350a286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from moviepy.editor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b87c588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '/Users/f004p74/Documents/dartmouth/projects/fSEND/task/f-send/public/sub_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3ec20d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seven SEND runs, 4 videos per run, shuffled within run\n",
    "send_run1 = [\"ID128_vid5\",\"ID117_vid4\",\"ID181_vid6\",\"ID124_vid6\"]\n",
    "send_run2 = [\"ID153_vid3\",\"ID131_vid2\",\"ID145_vid4\",\"ID120_vid4\"]\n",
    "send_run3 = [\"ID165_vid7\",\"ID112_vid1\",\"ID127_vid3\",\"ID113_vid4\"]\n",
    "send_run4 = [\"ID180_vid6\",\"ID170_vid7\",\"ID164_vid3\",\"ID118_vid1\"]\n",
    "send_run5 = [\"ID111_vid3\",\"ID116_vid2\",\"ID174_vid2\",\"ID129_vid6\"]\n",
    "send_run6 = [\"ID137_vid6\",\"ID179_vid3\",\"ID141_vid1\",\"ID171_vid5\"]\n",
    "send_run7 = [\"ID147_vid4\",\"ID123_vid3\",\"ID169_vid2\",\"ID121_vid6\"]\n",
    "\n",
    "send_runs = [send_run1,send_run2,send_run3,send_run4,\n",
    "            send_run5,send_run6,send_run7]\n",
    "\n",
    "# One NarratedThought run, shuffled order\n",
    "narr_version = [[['physical-v1'],['stutterer-v1']],\n",
    "                [['physical-v2'],['stutterer-v2']]]\n",
    "\n",
    "for i in range(3,6):\n",
    "    random.seed(i)\n",
    "    \n",
    "    for k in send_runs:\n",
    "        random.shuffle(k)\n",
    "        \n",
    "    for z in narr_version:\n",
    "        random.shuffle(z)\n",
    "        \n",
    "    random.shuffle(send_runs)\n",
    "    random.shuffle(narr_version)\n",
    "    \n",
    "    run_sequence = []\n",
    "    \n",
    "    if i % 2 == 0: #Even-numbered subjects watch NarratedThought videos first, SEND second.\n",
    "        for narr_list in narr_version[0]:\n",
    "            run_sequence.append(narr_list)\n",
    "        for sub_list in send_runs:\n",
    "            run_sequence.append(sub_list)\n",
    "            \n",
    "    else: # odd-numbered subjects watch SEND first, NarrThought last. \n",
    "        for sub_list in send_runs:\n",
    "            run_sequence.append(sub_list)\n",
    "        for narr_list in narr_version[1]:\n",
    "            run_sequence.append(narr_list)\n",
    "        \n",
    "    sequence_dict = {}\n",
    "\n",
    "    for ix, sub_list in enumerate(run_sequence):\n",
    "        sequence_dict[str(ix+1)] = {}\n",
    "        for num,video in enumerate(sub_list):\n",
    "            sequence_dict[str(ix+1)][sub_list[num]] = {}\n",
    "    \n",
    "    for v in sequence_dict.keys():\n",
    "        for thing in sequence_dict[v]:\n",
    "            try:\n",
    "                clip = VideoFileClip(\"/Users/f004p74/Documents/dartmouth/projects/fSEND/task/f-send/public/stimuli/\"+str(thing)+\".mp4\")\n",
    "                duration = clip.duration * 1000\n",
    "            except:\n",
    "                clip = VideoFileClip(\"/Users/f004p74/Documents/dartmouth/projects/fSEND/task/f-send/public/stimuli/\"+str(thing)+\".mp4\")\n",
    "                duration = clip.duration * 1000\n",
    "\n",
    "            sequence_dict[v][thing] = int(duration)\n",
    "    \n",
    "            \n",
    "    with open(out_path+'sub_'+str(i)+'_run-sequence.json', 'w') as fp:\n",
    "        json.dump(sequence_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2457505",
   "metadata": {},
   "source": [
    "# fSEND post-scan trait impressions\n",
    "\n",
    "After the participant watches the 30 individuals narrate their personal stories, we will ask them to make trait impressions on each of those individuals, for the following six traits: nosy, bossy, easygoing, rebellious, humble, and conscientious. Faces and trait presentation will be randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f59b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/Users/f004p74/Documents/dartmouth/projects/fSEND/survey/survey-app/client/public/images\"\n",
    "out_path = \"/Users/f004p74/Documents/dartmouth/projects/fSEND/survey/survey-app/client/src/trialOrders/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99d7ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [x.split('.png')[0] for x in os.listdir(img_path)]\n",
    "imgs = [x for x in imgs if '.DS_Store' not in x]\n",
    "\n",
    "traits = ['bossy', 'nosy','easygoing','rebellious','humble', 'conscientious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9cf540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,71):\n",
    "    random.seed(i)\n",
    "    random.shuffle(traits)\n",
    "    \n",
    "    img_order_dict = {} \n",
    "\n",
    "    for trait in traits:\n",
    "            img_order_dict[str(trait)] = {}\n",
    "\n",
    "    for item in img_order_dict.keys():\n",
    "        random.shuffle(imgs)\n",
    "        for img in imgs:\n",
    "            img_order_dict[item][img] = {}        \n",
    "    \n",
    "    with open(out_path+'sub_'+str(i)+'_trait-judgements.json', 'w') as fp:\n",
    "        json.dump(img_order_dict, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc0fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af27ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9bd45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
